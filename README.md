# Aron Mandrella ‚Äì Praca Magisterska (2020)
## Opis
Celem pracy by≈Ço znalezienie sztucznej sieci neuronowej s≈Çu≈ºƒÖcej do klasyfikacji d≈∫wiƒôk√≥w perkusyjnych zapewniajƒÖcej wysokƒÖ dok≈Çadno≈õƒá. NajwiƒôkszƒÖ uwagƒô przy≈Ço≈ºono do konwolucyjnych sieci neuronowych. W ramach bada≈Ñ testowano r√≥≈ºne metody reprezentacji d≈∫wiƒôku i r√≥≈ºne techniki trenowania sieci neuronowych.
* [Pe≈Çen tekst pracy magisterskiej](https://github.com/am-portfolio/Praca-Magisterska/blob/main/AMandrella%20-%20Praca%20Magisterska.pdf)
* [Wyniki (na dysku Google)](https://drive.google.com/drive/folders/1CWwUyckJevgqcemdiRQTdpQhYnwwuz_g?usp=sharing)
## üß∞ Wykorzystane technologie i narzƒôdzia
* **Python**
* **TensorFlow 2, Librosa, Matplotlib, NumPy, Pandas, sklearn**
* **Spyder IDE**
## üéì Zdobyta bƒÖd≈∫ poszerzona wiedza
* Umiejƒôtno≈õƒá pozyskiwania informacji z angielskiej literatury naukowej
* Teoria z zakresu uczenia maszynowego i sieci neuronowych
* Metody normalizacji danych
* Algorytmy gradientowe
* Nowe metody uczenia sieci neuronowych (dropout, batch normalisation) 
* Metody analizy i reprezentacji d≈∫wiƒôku (transformacja Fouriera, spektrogram, transformacja ze sta≈Çym Q, transformata cosinusowa, wsp√≥≈Çczynniki mel-cepstralne)
* Metody walidacji modeli stworzonych metodƒÖ uczenia maszynowego (walidacja krzy≈ºowa, tablice pomy≈Çek, wska≈∫niki jako≈õci klasyfikacji itp.)
* Akademickie metody statystycznej analizy zebranych danych (np. wykresy pude≈Çkowe)
```python
# Modu≈Çy napisane na potrzeby pracy
from pymodules.mlevaluator import *
from pymodules.anntrainer import *
from pymodules.dnnmaker import*

import tensorflow as tf

# Podstawowa funkcja do tworzenia prostych sieci DNN:
# params: hidden_layers, layer_neurons
def createSalamonCNN(params, x_shape, num_labels):
    # Regularizer
    regularizer = None
    if(params["l2"] != 0):
        regularizer = tf.keras.regularizers.l2(params["l2"])
        
    # Model sieci
    model = tf.keras.models.Sequential()
    
    # Warstwa wejsciowa
    # I sekcja konwolucyjno poolingowa.
    model.add(tf.keras.layers.Conv2D(
        input_shape=(x_shape[0], x_shape[1], 1),
        kernel_size=(5,5), filters=24, activation='relu'))
    model.add(tf.keras.layers.MaxPool2D(pool_size=params["pool_size"]))
    
    # II sekcja konwolucyjno poolingowa.
    model.add(tf.keras.layers.Conv2D(
        kernel_size=(5,5), filters=48, activation='relu'))
    model.add(tf.keras.layers.MaxPool2D(pool_size=params["pool_size"]))
    
    # III sekcja konwolucyjno poolingowa.
    model.add(tf.keras.layers.Conv2D(
        kernel_size=(5,5), filters=48, activation='relu'))
    
    # Sp≈Çaszczanie wejscia
    model.add(tf.keras.layers.Flatten())
    
    # Ukryta warstwa gƒôsto po≈ÇƒÖczona
    if params["dropout"] == True:
        model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(
        64, activation=tf.nn.relu,
        kernel_regularizer=regularizer, bias_regularizer=None,
    )) 
        
    # Warstwa wyjsciowa (bez softmax)
    if params["dropout"] == True:
        model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(
        num_labels,
        kernel_regularizer=regularizer, bias_regularizer=None,
    ))
    
    return model
```
